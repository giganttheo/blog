<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Intro to DPP | my blog</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="Finite Determinantal Point Processes : This blog post is adapted from a school project ( in French ). The report is available here, and the companion python notebook here.
Most of our work is based on Alex Kulesza and Ben Taskar&rsquo;s papers, mostly Determinantal point processes for machine learning. We added extra and clearer proofs.
Definition : Quickly :
  a point process is defined as a measure of probability,">
    <meta name="generator" content="Hugo 0.76.5" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
    
      <link href="/giganttheo.github.io/dist/css/app.4fc0b62e4b82c997bb0041217cd6b979.css" rel="stylesheet">
    

    

    
      

    

    
    
    <meta property="og:title" content="Intro to DPP" />
<meta property="og:description" content="Finite Determinantal Point Processes : This blog post is adapted from a school project ( in French ). The report is available here, and the companion python notebook here.
Most of our work is based on Alex Kulesza and Ben Taskar&rsquo;s papers, mostly Determinantal point processes for machine learning. We added extra and clearer proofs.
Definition : Quickly :
  a point process is defined as a measure of probability," />
<meta property="og:type" content="article" />
<meta property="og:url" content="giganttheo.github.io/post/dpp/" />
<meta property="article:published_time" content="2020-07-01T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-07-01T00:00:00+00:00" />
<meta itemprop="name" content="Intro to DPP">
<meta itemprop="description" content="Finite Determinantal Point Processes : This blog post is adapted from a school project ( in French ). The report is available here, and the companion python notebook here.
Most of our work is based on Alex Kulesza and Ben Taskar&rsquo;s papers, mostly Determinantal point processes for machine learning. We added extra and clearer proofs.
Definition : Quickly :
  a point process is defined as a measure of probability,">
<meta itemprop="datePublished" content="2020-07-01T00:00:00+00:00" />
<meta itemprop="dateModified" content="2020-07-01T00:00:00+00:00" />
<meta itemprop="wordCount" content="480">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Intro to DPP"/>
<meta name="twitter:description" content="Finite Determinantal Point Processes : This blog post is adapted from a school project ( in French ). The report is available here, and the companion python notebook here.
Most of our work is based on Alex Kulesza and Ben Taskar&rsquo;s papers, mostly Determinantal point processes for machine learning. We added extra and clearer proofs.
Definition : Quickly :
  a point process is defined as a measure of probability,"/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-washed-red">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="giganttheo.github.io/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        my blog
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="giganttheo.github.io/contact/" title="Contact page">
              Contact
            </a>
          </li>
          
        </ul>
      
      















    </div>
  </div>
</nav>

    </div>
	<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        ARTICLES
      </aside>
      




  <div id="sharing" class="mt3">

    
    <a href="https://www.facebook.com/sharer.php?u=giganttheo.github.io/giganttheo.github.io/post/dpp/" class="facebook no-underline" aria-label="share on Facebook">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765,50.32h6.744V33.998h4.499l0.596-5.624h-5.095  l0.007-2.816c0-1.466,0.14-2.253,2.244-2.253h2.812V17.68h-4.5c-5.405,0-7.307,2.729-7.307,7.317v3.377h-3.369v5.625h3.369V50.32z   M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>

    </a>

    
    
    <a href="https://twitter.com/share?url=giganttheo.github.io/giganttheo.github.io/post/dpp/&amp;text=Intro%20to%20DPP" class="twitter no-underline" aria-label="share on Twitter">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/></svg>

    </a>

    
    <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=giganttheo.github.io/giganttheo.github.io/post/dpp/&amp;title=Intro%20to%20DPP" class="linkedin no-underline" aria-label="share on LinkedIn">
      <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

    </a>
  </div>


      <h1 class="f1 athelas mt3 mb1">Intro to DPP</h1>
      
      
      <time class="f6 mv4 dib tracked" datetime="2020-07-01T00:00:00Z">July 1, 2020</time>

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><h2 id="finite-determinantal-point-processes-">Finite Determinantal Point Processes :</h2>
<p>This blog post is adapted from a school project ( in French ).
The report is available <a href="https://github.com/giganttheo/DPP/blob/master/28_Rapport%20Tuteur%20Cassiop%C3%A9e.pdf"><strong>here</strong></a>, and the companion python notebook <a href="https://github.com/giganttheo/DPP/blob/master/DPP_Notebook.ipynb"><strong>here</strong></a>.</p>
<p>Most of our work is based on Alex Kulesza and Ben Taskar&rsquo;s papers, mostly
<em>Determinantal point processes for machine learning</em>.
We added extra and clearer proofs.</p>
<h2 id="definition-">Definition :</h2>
<p>Quickly :</p>
<ul>
<li>
<p>a point process is defined as a measure of probability,</p>
</li>
<li>
<p>a point process is <em>determinantal</em> when there is a matrix $K$, known as a Kernel matrix, such that $\rm \mathbb{P}(X \in \mathcal{P(Y}|Y \subset X ) = \text{det}(K_Y)$ where $K_Y$ is the restriction of $K$ to the elements of $Y$.</p>
</li>
<li>
<p>Another definition of a determinantal point process is by the $L$-ensembles : a measure of probability $\rm \mathbb{P}_L(Y = y) \propto \text{det}(L_Y)$ with $L_Y$ related to $K_Y$ by the formula :
$$K = L(L + I)^{-1}$$</p>
</li>
</ul>
<p>The interesting thing with determinantal point processes is mainly to sample from them to have some data with a repulsive phenomenon. For that matter, the simplest algorithm is known as the <em>Spectral Method</em> and is defined as follow :</p>
<p><img src="https://i.ibb.co/pKKgf8Y/Capture.png" alt="Spectral Method algorithm"></p>
<h2 id="code">Code</h2>
<p>Now that we know a little about finite determinantal point processes, let&rsquo;s go in Python
and code the spectral algorithm to sample from finite DPPs defined by the eigenvectors &amp;
eigenvalues of $K_L$ :</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">spectral_method</span>(lambda_L, v_L):
  N <span style="color:#f92672">=</span> lambda_L<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]
  J <span style="color:#f92672">=</span> [] <span style="color:#75715e"># J is the set of the indices of the eigenvectors in the elementary DPP which we sample from in the second part of the algorithm</span>
  <span style="color:#66d9ef">for</span> n <span style="color:#f92672">in</span> range(N):
      <span style="color:#66d9ef">if</span> random<span style="color:#f92672">.</span>random() <span style="color:#f92672">&lt;</span> (lambda_L[n] <span style="color:#f92672">/</span> (<span style="color:#ae81ff">1</span> <span style="color:#f92672">+</span> lambda_L[n])):
        <span style="color:#75715e"># each eigenvector has a probability `lambda_L[n] / (1 + lambda_L[n])` of being part of J</span>
        J<span style="color:#f92672">.</span>append(n)
  V <span style="color:#f92672">=</span> [v_L[n] <span style="color:#66d9ef">for</span> n <span style="color:#f92672">in</span> J]
  Y <span style="color:#f92672">=</span> []
  <span style="color:#75715e">#End of the first part of the algorithm : now we will sample from the elementary DPP defined by the eigenvectors in V</span>
  <span style="color:#66d9ef">while</span> len(V) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>:
      rd <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>random()
      s <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
      i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
      <span style="color:#66d9ef">while</span> rd <span style="color:#f92672">&gt;</span> s:
        <span style="color:#75715e"># this loop is for choosing $i$ in $\mathcal(Y)$ with a probability $\sigma_{v \in V}(np.dot(v.T,ei)**2) / len(V)$</span>
        ei <span style="color:#f92672">=</span> [<span style="color:#ae81ff">0</span> <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(N) ]
        ei[i] <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
        ei <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(ei)
        <span style="color:#66d9ef">for</span> v <span style="color:#f92672">in</span> V:
          s <span style="color:#f92672">+=</span> (np<span style="color:#f92672">.</span>dot(v<span style="color:#f92672">.</span>T,ei)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>) <span style="color:#f92672">/</span> len(V) 
        i <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
      Y<span style="color:#f92672">.</span>append(i)
      <span style="color:#66d9ef">if</span> len(V) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">1</span> :
          <span style="color:#75715e"># We project V on the orthogonal complement of ej then deduce an orthonormal basis V_orth of rank Card(V) - 1</span>
          V_orth <span style="color:#f92672">=</span> []
          <span style="color:#66d9ef">for</span> v <span style="color:#f92672">in</span> V :
              V_orth<span style="color:#f92672">.</span>append(v <span style="color:#f92672">-</span> np<span style="color:#f92672">.</span>dot(v<span style="color:#f92672">.</span>T,ei)<span style="color:#f92672">*</span>ei)
          <span style="color:#75715e"># the new V_J is an orthogonal basis</span>
          V <span style="color:#f92672">=</span> scipy<span style="color:#f92672">.</span>linalg<span style="color:#f92672">.</span>orth(np<span style="color:#f92672">.</span>array(V_orth[:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>])<span style="color:#f92672">.</span>T)<span style="color:#f92672">.</span>T
          <span style="color:#75715e"># we replace V by this new orthonormal basis, the cardinality of V is reduce by 1 at each loop</span>
      <span style="color:#66d9ef">else</span> :
        <span style="color:#75715e"># if the cardinality of V is 1, we exit the loop</span>
        V <span style="color:#f92672">=</span> []
  <span style="color:#66d9ef">return</span> Y
</code></pre></div><p>Thanks for reading me, if you have any comment or questions, you can join me @ <a href="mailto:theo.gigant@telecom-sudparis.eu">theo.gigant@telecom-sudparis.eu</a></p>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-washed-red bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="giganttheo.github.io" >
    &copy;  my blog 2020 
  </a>
    <div>














</div>
  </div>
</footer>

    

  <script src="/giganttheo.github.io/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
